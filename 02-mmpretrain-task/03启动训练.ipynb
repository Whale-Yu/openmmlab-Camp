{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e523247-543d-4a58-9f62-5d5faf00e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('mmpretrain')\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a2c81f-273a-497c-9be5-06056a9d5431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a61c2-a5ec-4b55-9f54-8274e1d327c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training command is /root/miniconda3/envs/myconda/bin/python /mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/mmpretrain/.mim/tools/train.py myconfig/resnet50_fruit30.py --launcher none --work-dir=work_dirs. \n",
      "06/06 15:32:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1637683315\n",
      "    GPU 0: NVIDIA A16\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.3, V11.3.109\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.12.1+cu113\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu113\n",
      "    OpenCV: 4.6.0\n",
      "    MMEngine: 0.7.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: None\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "06/06 15:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "model = dict(\n",
      "    type='ImageClassifier',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(3, ),\n",
      "        style='pytorch'),\n",
      "    neck=dict(type='GlobalAveragePooling'),\n",
      "    head=dict(\n",
      "        type='LinearClsHead',\n",
      "        num_classes=30,\n",
      "        in_channels=2048,\n",
      "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "        topk=(1, 5)),\n",
      "    init_cfg=dict(\n",
      "        type='Pretrained',\n",
      "        checkpoint=\n",
      "        'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'\n",
      "    ))\n",
      "dataset_type = 'CustomDataset'\n",
      "data_preprocessor = dict(\n",
      "    num_classes=1000,\n",
      "    mean=[123.675, 116.28, 103.53],\n",
      "    std=[58.395, 57.12, 57.375],\n",
      "    to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='RandomResizedCrop', scale=224),\n",
      "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "    dict(type='PackInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='PackInputs')\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/fruit30_dataset/training_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='RandomResizedCrop', scale=224),\n",
      "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True))\n",
      "val_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/fruit30_dataset/val_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "val_evaluator = dict(type='Accuracy', topk=(1, 5))\n",
      "test_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/fruit30_dataset/val_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "test_evaluator = dict(type='Accuracy', topk=(1, 5))\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001))\n",
      "param_scheduler = dict(\n",
      "    type='MultiStepLR', by_epoch=True, milestones=[30, 60, 90], gamma=0.1)\n",
      "train_cfg = dict(by_epoch=True, max_epochs=10, val_interval=1)\n",
      "val_cfg = dict()\n",
      "test_cfg = dict()\n",
      "default_scope = 'mmpretrain'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=5),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', interval=5, save_best='auto'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='VisualizationHook', enable=False))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='UniversalVisualizer', vis_backends=[dict(type='LocalVisBackend')])\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume = False\n",
      "randomness = dict(seed=None, deterministic=False)\n",
      "launcher = 'none'\n",
      "work_dir = 'work_dirs'\n",
      "\n",
      "06/06 15:32:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "06/06 15:32:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "06/06 15:32:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth\n",
      "06/06 15:32:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth\n",
      "06/06 15:32:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for head.fc.weight: copying a param with shape torch.Size([1000, 2048]) from checkpoint, the shape in current model is torch.Size([30, 2048]).\n",
      "size mismatch for head.fc.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([30]).\n",
      "06/06 15:32:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "06/06 15:32:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "06/06 15:32:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain/work_dirs.\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "06/06 15:32:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 5/96]  lr: 1.0000e-03  eta: 0:23:32  time: 1.4792  data_time: 0.4961  memory: 2943  loss: 3.4490\n",
      "06/06 15:32:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][10/96]  lr: 1.0000e-03  eta: 0:14:52  time: 0.9393  data_time: 0.2488  memory: 2943  loss: 3.4127\n",
      "06/06 15:32:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][15/96]  lr: 1.0000e-03  eta: 0:11:57  time: 0.3993  data_time: 0.0013  memory: 2943  loss: 3.3926\n",
      "06/06 15:32:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][20/96]  lr: 1.0000e-03  eta: 0:10:29  time: 0.3991  data_time: 0.0011  memory: 2943  loss: 3.3879\n",
      "06/06 15:32:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][25/96]  lr: 1.0000e-03  eta: 0:09:35  time: 0.3994  data_time: 0.0012  memory: 2943  loss: 3.2873\n",
      "06/06 15:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][30/96]  lr: 1.0000e-03  eta: 0:08:58  time: 0.3998  data_time: 0.0012  memory: 2943  loss: 3.1527\n",
      "06/06 15:32:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][35/96]  lr: 1.0000e-03  eta: 0:08:32  time: 0.4003  data_time: 0.0011  memory: 2943  loss: 3.0541\n",
      "06/06 15:32:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][40/96]  lr: 1.0000e-03  eta: 0:08:11  time: 0.4008  data_time: 0.0012  memory: 2943  loss: 2.9461\n",
      "06/06 15:32:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][45/96]  lr: 1.0000e-03  eta: 0:07:55  time: 0.4008  data_time: 0.0012  memory: 2943  loss: 2.8450\n",
      "06/06 15:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][50/96]  lr: 1.0000e-03  eta: 0:07:42  time: 0.4008  data_time: 0.0012  memory: 2943  loss: 2.8000\n",
      "06/06 15:32:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][55/96]  lr: 1.0000e-03  eta: 0:07:30  time: 0.4010  data_time: 0.0012  memory: 2943  loss: 2.6649\n",
      "06/06 15:32:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][60/96]  lr: 1.0000e-03  eta: 0:07:21  time: 0.4009  data_time: 0.0011  memory: 2943  loss: 2.5634\n",
      "06/06 15:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][65/96]  lr: 1.0000e-03  eta: 0:07:12  time: 0.4012  data_time: 0.0011  memory: 2943  loss: 2.4782\n",
      "06/06 15:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][70/96]  lr: 1.0000e-03  eta: 0:07:04  time: 0.4014  data_time: 0.0011  memory: 2943  loss: 2.2921\n",
      "06/06 15:32:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][75/96]  lr: 1.0000e-03  eta: 0:06:58  time: 0.4012  data_time: 0.0012  memory: 2943  loss: 2.1578\n",
      "06/06 15:32:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][80/96]  lr: 1.0000e-03  eta: 0:06:51  time: 0.4015  data_time: 0.0012  memory: 2943  loss: 2.0177\n",
      "06/06 15:32:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][85/96]  lr: 1.0000e-03  eta: 0:06:46  time: 0.4017  data_time: 0.0012  memory: 2943  loss: 1.9120\n",
      "06/06 15:32:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][90/96]  lr: 1.0000e-03  eta: 0:06:40  time: 0.4015  data_time: 0.0011  memory: 2943  loss: 1.8978\n",
      "06/06 15:32:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][95/96]  lr: 1.0000e-03  eta: 0:06:35  time: 0.4015  data_time: 0.0011  memory: 2943  loss: 1.7929\n",
      "06/06 15:32:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet50_fruit30_20230606_153206\n",
      "06/06 15:32:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 5/41]    eta: 0:00:09  time: 0.2709  data_time: 0.1439  memory: 1211  \n",
      "06/06 15:32:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][10/41]    eta: 0:00:06  time: 0.1983  data_time: 0.0723  memory: 615  \n",
      "06/06 15:33:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][15/41]    eta: 0:00:04  time: 0.1252  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][20/41]    eta: 0:00:03  time: 0.1249  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][25/41]    eta: 0:00:02  time: 0.1253  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][30/41]    eta: 0:00:01  time: 0.1252  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][35/41]    eta: 0:00:00  time: 0.1260  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][40/41]    eta: 0:00:00  time: 0.1260  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][41/41]    accuracy/top1: 76.2529  accuracy/top5: 95.9136  data_time: 0.0180  time: 0.1419\n",
      "06/06 15:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 76.2529 accuracy/top1 at 1 epoch is saved to best_accuracy_top1_epoch_1.pth.\n",
      "06/06 15:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 5/96]  lr: 1.0000e-03  eta: 0:06:29  time: 0.3995  data_time: 0.0239  memory: 2943  loss: 1.5945\n",
      "06/06 15:33:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][10/96]  lr: 1.0000e-03  eta: 0:06:25  time: 0.4239  data_time: 0.0240  memory: 2943  loss: 1.4389\n",
      "06/06 15:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][15/96]  lr: 1.0000e-03  eta: 0:06:21  time: 0.4021  data_time: 0.0012  memory: 2943  loss: 1.3006\n",
      "06/06 15:33:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][20/96]  lr: 1.0000e-03  eta: 0:06:17  time: 0.4029  data_time: 0.0012  memory: 2943  loss: 1.3045\n",
      "06/06 15:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][25/96]  lr: 1.0000e-03  eta: 0:06:13  time: 0.4028  data_time: 0.0012  memory: 2943  loss: 1.3457\n",
      "06/06 15:33:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][30/96]  lr: 1.0000e-03  eta: 0:06:10  time: 0.4026  data_time: 0.0012  memory: 2943  loss: 1.2670\n",
      "06/06 15:33:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][35/96]  lr: 1.0000e-03  eta: 0:06:06  time: 0.4025  data_time: 0.0011  memory: 2943  loss: 1.2115\n",
      "06/06 15:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][40/96]  lr: 1.0000e-03  eta: 0:06:03  time: 0.4025  data_time: 0.0011  memory: 2943  loss: 1.1386\n",
      "06/06 15:33:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][45/96]  lr: 1.0000e-03  eta: 0:05:59  time: 0.4027  data_time: 0.0011  memory: 2943  loss: 1.0630\n",
      "06/06 15:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][50/96]  lr: 1.0000e-03  eta: 0:05:56  time: 0.4028  data_time: 0.0012  memory: 2943  loss: 1.1173\n",
      "06/06 15:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][55/96]  lr: 1.0000e-03  eta: 0:05:53  time: 0.4029  data_time: 0.0012  memory: 2943  loss: 1.1059\n",
      "06/06 15:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][60/96]  lr: 1.0000e-03  eta: 0:05:50  time: 0.4029  data_time: 0.0012  memory: 2943  loss: 1.0803\n",
      "06/06 15:33:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][65/96]  lr: 1.0000e-03  eta: 0:05:47  time: 0.4029  data_time: 0.0011  memory: 2943  loss: 1.0500\n",
      "06/06 15:33:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][70/96]  lr: 1.0000e-03  eta: 0:05:44  time: 0.4029  data_time: 0.0011  memory: 2943  loss: 1.0089\n",
      "06/06 15:33:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][75/96]  lr: 1.0000e-03  eta: 0:05:41  time: 0.4030  data_time: 0.0011  memory: 2943  loss: 1.0276\n",
      "06/06 15:33:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][80/96]  lr: 1.0000e-03  eta: 0:05:38  time: 0.4031  data_time: 0.0011  memory: 2943  loss: 1.0221\n",
      "06/06 15:33:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][85/96]  lr: 1.0000e-03  eta: 0:05:36  time: 0.4032  data_time: 0.0012  memory: 2943  loss: 0.9913\n",
      "06/06 15:33:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][90/96]  lr: 1.0000e-03  eta: 0:05:33  time: 0.4032  data_time: 0.0011  memory: 2943  loss: 0.9126\n",
      "06/06 15:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][95/96]  lr: 1.0000e-03  eta: 0:05:30  time: 0.4031  data_time: 0.0011  memory: 2943  loss: 0.8285\n",
      "06/06 15:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet50_fruit30_20230606_153206\n",
      "06/06 15:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 5/41]    eta: 0:00:06  time: 0.1469  data_time: 0.0278  memory: 1211  \n",
      "06/06 15:33:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][10/41]    eta: 0:00:04  time: 0.1527  data_time: 0.0278  memory: 615  \n",
      "06/06 15:33:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][15/41]    eta: 0:00:03  time: 0.1261  data_time: 0.0010  memory: 615  \n",
      "06/06 15:33:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][20/41]    eta: 0:00:02  time: 0.1259  data_time: 0.0009  memory: 615  \n",
      "06/06 15:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][25/41]    eta: 0:00:02  time: 0.1260  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][30/41]    eta: 0:00:01  time: 0.1258  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][35/41]    eta: 0:00:00  time: 0.1256  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][40/41]    eta: 0:00:00  time: 0.1255  data_time: 0.0005  memory: 615  \n",
      "06/06 15:33:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][41/41]    accuracy/top1: 83.2691  accuracy/top5: 97.7641  data_time: 0.0071  time: 0.1297\n",
      "06/06 15:33:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain/work_dirs/best_accuracy_top1_epoch_1.pth is removed\n",
      "06/06 15:33:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 83.2691 accuracy/top1 at 2 epoch is saved to best_accuracy_top1_epoch_2.pth.\n",
      "06/06 15:33:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 5/96]  lr: 1.0000e-03  eta: 0:05:27  time: 0.4049  data_time: 0.0280  memory: 2943  loss: 0.8660\n",
      "06/06 15:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][10/96]  lr: 1.0000e-03  eta: 0:05:24  time: 0.4291  data_time: 0.0281  memory: 2943  loss: 0.8897\n",
      "06/06 15:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][15/96]  lr: 1.0000e-03  eta: 0:05:22  time: 0.4029  data_time: 0.0012  memory: 2943  loss: 0.8505\n",
      "06/06 15:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][20/96]  lr: 1.0000e-03  eta: 0:05:19  time: 0.4033  data_time: 0.0012  memory: 2943  loss: 0.7359\n",
      "06/06 15:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][25/96]  lr: 1.0000e-03  eta: 0:05:17  time: 0.4032  data_time: 0.0012  memory: 2943  loss: 0.7563\n",
      "06/06 15:34:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][30/96]  lr: 1.0000e-03  eta: 0:05:14  time: 0.4030  data_time: 0.0012  memory: 2943  loss: 0.7993\n",
      "06/06 15:34:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][35/96]  lr: 1.0000e-03  eta: 0:05:12  time: 0.4032  data_time: 0.0012  memory: 2943  loss: 0.6887\n",
      "06/06 15:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][40/96]  lr: 1.0000e-03  eta: 0:05:09  time: 0.4034  data_time: 0.0013  memory: 2943  loss: 0.6864\n",
      "06/06 15:34:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][45/96]  lr: 1.0000e-03  eta: 0:05:07  time: 0.4035  data_time: 0.0012  memory: 2943  loss: 0.7668\n",
      "06/06 15:34:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][50/96]  lr: 1.0000e-03  eta: 0:05:04  time: 0.4034  data_time: 0.0012  memory: 2943  loss: 0.7283\n",
      "06/06 15:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][55/96]  lr: 1.0000e-03  eta: 0:05:02  time: 0.4033  data_time: 0.0013  memory: 2943  loss: 0.6546\n",
      "06/06 15:34:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][60/96]  lr: 1.0000e-03  eta: 0:04:59  time: 0.4033  data_time: 0.0012  memory: 2943  loss: 0.6448\n",
      "06/06 15:34:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][65/96]  lr: 1.0000e-03  eta: 0:04:57  time: 0.4034  data_time: 0.0012  memory: 2943  loss: 0.6990\n",
      "06/06 15:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][70/96]  lr: 1.0000e-03  eta: 0:04:55  time: 0.4034  data_time: 0.0012  memory: 2943  loss: 0.7196\n",
      "06/06 15:34:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][75/96]  lr: 1.0000e-03  eta: 0:04:52  time: 0.4032  data_time: 0.0011  memory: 2943  loss: 0.7000\n",
      "06/06 15:34:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][80/96]  lr: 1.0000e-03  eta: 0:04:50  time: 0.4034  data_time: 0.0012  memory: 2943  loss: 0.6616\n",
      "06/06 15:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][85/96]  lr: 1.0000e-03  eta: 0:04:48  time: 0.4036  data_time: 0.0012  memory: 2943  loss: 0.5900\n",
      "06/06 15:34:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][90/96]  lr: 1.0000e-03  eta: 0:04:45  time: 0.4035  data_time: 0.0011  memory: 2943  loss: 0.5816\n",
      "06/06 15:34:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][95/96]  lr: 1.0000e-03  eta: 0:04:43  time: 0.4034  data_time: 0.0011  memory: 2943  loss: 0.6258\n",
      "06/06 15:34:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet50_fruit30_20230606_153206\n",
      "06/06 15:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][ 5/41]    eta: 0:00:06  time: 0.1537  data_time: 0.0345  memory: 1211  \n",
      "06/06 15:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][10/41]    eta: 0:00:04  time: 0.1593  data_time: 0.0346  memory: 615  \n",
      "06/06 15:34:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][15/41]    eta: 0:00:03  time: 0.1257  data_time: 0.0006  memory: 615  \n",
      "06/06 15:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][20/41]    eta: 0:00:02  time: 0.1259  data_time: 0.0006  memory: 615  \n",
      "06/06 15:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][25/41]    eta: 0:00:02  time: 0.1259  data_time: 0.0006  memory: 615  \n",
      "06/06 15:34:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][30/41]    eta: 0:00:01  time: 0.1258  data_time: 0.0006  memory: 615  \n",
      "06/06 15:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][35/41]    eta: 0:00:00  time: 0.1258  data_time: 0.0005  memory: 615  \n",
      "06/06 15:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][40/41]    eta: 0:00:00  time: 0.1256  data_time: 0.0005  memory: 615  \n",
      "06/06 15:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][41/41]    accuracy/top1: 88.8204  accuracy/top5: 98.9977  data_time: 0.0087  time: 0.1313\n",
      "06/06 15:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain/work_dirs/best_accuracy_top1_epoch_2.pth is removed\n",
      "06/06 15:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 88.8204 accuracy/top1 at 3 epoch is saved to best_accuracy_top1_epoch_3.pth.\n",
      "06/06 15:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 5/96]  lr: 1.0000e-03  eta: 0:04:40  time: 0.4052  data_time: 0.0278  memory: 2943  loss: 0.6106\n",
      "06/06 15:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][10/96]  lr: 1.0000e-03  eta: 0:04:38  time: 0.4294  data_time: 0.0278  memory: 2943  loss: 0.5089\n",
      "06/06 15:34:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][15/96]  lr: 1.0000e-03  eta: 0:04:36  time: 0.4030  data_time: 0.0012  memory: 2943  loss: 0.6293\n",
      "06/06 15:34:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][20/96]  lr: 1.0000e-03  eta: 0:04:33  time: 0.4031  data_time: 0.0012  memory: 2943  loss: 0.6096\n",
      "06/06 15:34:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][25/96]  lr: 1.0000e-03  eta: 0:04:31  time: 0.4031  data_time: 0.0012  memory: 2943  loss: 0.4726\n",
      "06/06 15:34:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][30/96]  lr: 1.0000e-03  eta: 0:04:29  time: 0.4032  data_time: 0.0012  memory: 2943  loss: 0.5090\n",
      "06/06 15:34:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][35/96]  lr: 1.0000e-03  eta: 0:04:26  time: 0.4033  data_time: 0.0012  memory: 2943  loss: 0.5625\n",
      "06/06 15:34:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][40/96]  lr: 1.0000e-03  eta: 0:04:24  time: 0.4032  data_time: 0.0012  memory: 2943  loss: 0.5390\n",
      "06/06 15:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][45/96]  lr: 1.0000e-03  eta: 0:04:22  time: 0.4032  data_time: 0.0011  memory: 2943  loss: 0.5442\n",
      "06/06 15:34:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][50/96]  lr: 1.0000e-03  eta: 0:04:20  time: 0.4033  data_time: 0.0011  memory: 2943  loss: 0.5312\n",
      "06/06 15:35:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][55/96]  lr: 1.0000e-03  eta: 0:04:18  time: 0.4034  data_time: 0.0012  memory: 2943  loss: 0.5161\n",
      "06/06 15:35:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][60/96]  lr: 1.0000e-03  eta: 0:04:15  time: 0.4034  data_time: 0.0013  memory: 2943  loss: 0.5073\n",
      "06/06 15:35:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][65/96]  lr: 1.0000e-03  eta: 0:04:13  time: 0.4035  data_time: 0.0013  memory: 2943  loss: 0.5079\n",
      "06/06 15:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][70/96]  lr: 1.0000e-03  eta: 0:04:11  time: 0.4036  data_time: 0.0013  memory: 2943  loss: 0.5272\n",
      "06/06 15:35:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][75/96]  lr: 1.0000e-03  eta: 0:04:09  time: 0.4035  data_time: 0.0012  memory: 2943  loss: 0.5087\n",
      "06/06 15:35:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][80/96]  lr: 1.0000e-03  eta: 0:04:06  time: 0.4032  data_time: 0.0011  memory: 2943  loss: 0.5227\n",
      "06/06 15:35:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][85/96]  lr: 1.0000e-03  eta: 0:04:04  time: 0.4034  data_time: 0.0011  memory: 2943  loss: 0.5083\n",
      "06/06 15:35:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][90/96]  lr: 1.0000e-03  eta: 0:04:02  time: 0.4033  data_time: 0.0012  memory: 2943  loss: 0.4569\n",
      "06/06 15:35:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][95/96]  lr: 1.0000e-03  eta: 0:04:00  time: 0.4032  data_time: 0.0011  memory: 2943  loss: 0.5255\n",
      "06/06 15:35:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet50_fruit30_20230606_153206\n",
      "06/06 15:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][ 5/41]    eta: 0:00:06  time: 0.1522  data_time: 0.0327  memory: 1211  \n",
      "06/06 15:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][10/41]    eta: 0:00:04  time: 0.1582  data_time: 0.0327  memory: 615  \n",
      "06/06 15:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][15/41]    eta: 0:00:03  time: 0.1263  data_time: 0.0006  memory: 615  \n",
      "06/06 15:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][20/41]    eta: 0:00:02  time: 0.1257  data_time: 0.0006  memory: 615  \n",
      "06/06 15:35:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][25/41]    eta: 0:00:02  time: 0.1260  data_time: 0.0006  memory: 615  \n",
      "06/06 15:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][30/41]    eta: 0:00:01  time: 0.1258  data_time: 0.0006  memory: 615  \n",
      "06/06 15:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][35/41]    eta: 0:00:00  time: 0.1259  data_time: 0.0006  memory: 615  \n",
      "06/06 15:35:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][40/41]    eta: 0:00:00  time: 0.1257  data_time: 0.0006  memory: 615  \n",
      "06/06 15:35:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][41/41]    accuracy/top1: 90.5166  accuracy/top5: 98.9206  data_time: 0.0083  time: 0.1310\n",
      "06/06 15:35:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain/work_dirs/best_accuracy_top1_epoch_3.pth is removed\n",
      "06/06 15:35:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 90.5166 accuracy/top1 at 4 epoch is saved to best_accuracy_top1_epoch_4.pth.\n",
      "06/06 15:35:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 5/96]  lr: 1.0000e-03  eta: 0:03:57  time: 0.4002  data_time: 0.0231  memory: 2943  loss: 0.4763\n",
      "06/06 15:35:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][10/96]  lr: 1.0000e-03  eta: 0:03:55  time: 0.4245  data_time: 0.0232  memory: 2943  loss: 0.4374\n",
      "06/06 15:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][15/96]  lr: 1.0000e-03  eta: 0:03:53  time: 0.4029  data_time: 0.0012  memory: 2943  loss: 0.4480\n",
      "06/06 15:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][20/96]  lr: 1.0000e-03  eta: 0:03:51  time: 0.4030  data_time: 0.0012  memory: 2943  loss: 0.4814\n",
      "06/06 15:35:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][25/96]  lr: 1.0000e-03  eta: 0:03:49  time: 0.4030  data_time: 0.0012  memory: 2943  loss: 0.5134\n",
      "06/06 15:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][30/96]  lr: 1.0000e-03  eta: 0:03:46  time: 0.4032  data_time: 0.0013  memory: 2943  loss: 0.4709\n",
      "06/06 15:35:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][35/96]  lr: 1.0000e-03  eta: 0:03:44  time: 0.4032  data_time: 0.0013  memory: 2943  loss: 0.4512\n",
      "06/06 15:35:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][40/96]  lr: 1.0000e-03  eta: 0:03:42  time: 0.4031  data_time: 0.0012  memory: 2943  loss: 0.3756\n",
      "06/06 15:35:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][45/96]  lr: 1.0000e-03  eta: 0:03:40  time: 0.4031  data_time: 0.0012  memory: 2943  loss: 0.3438\n",
      "06/06 15:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][50/96]  lr: 1.0000e-03  eta: 0:03:38  time: 0.4030  data_time: 0.0012  memory: 2943  loss: 0.4013\n",
      "06/06 15:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][55/96]  lr: 1.0000e-03  eta: 0:03:36  time: 0.4031  data_time: 0.0012  memory: 2943  loss: 0.4262\n",
      "06/06 15:35:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][60/96]  lr: 1.0000e-03  eta: 0:03:33  time: 0.4031  data_time: 0.0012  memory: 2943  loss: 0.3693\n",
      "06/06 15:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][65/96]  lr: 1.0000e-03  eta: 0:03:31  time: 0.4031  data_time: 0.0011  memory: 2943  loss: 0.3639\n",
      "06/06 15:35:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][70/96]  lr: 1.0000e-03  eta: 0:03:29  time: 0.4030  data_time: 0.0012  memory: 2943  loss: 0.4028\n",
      "06/06 15:35:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][75/96]  lr: 1.0000e-03  eta: 0:03:27  time: 0.4032  data_time: 0.0012  memory: 2943  loss: 0.4436\n",
      "06/06 15:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][80/96]  lr: 1.0000e-03  eta: 0:03:25  time: 0.4034  data_time: 0.0015  memory: 2943  loss: 0.4067\n",
      "06/06 15:36:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][85/96]  lr: 1.0000e-03  eta: 0:03:23  time: 0.4032  data_time: 0.0014  memory: 2943  loss: 0.3694\n",
      "06/06 15:36:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][90/96]  lr: 1.0000e-03  eta: 0:03:21  time: 0.4030  data_time: 0.0011  memory: 2943  loss: 0.3668\n",
      "06/06 15:36:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][95/96]  lr: 1.0000e-03  eta: 0:03:19  time: 0.4028  data_time: 0.0011  memory: 2943  loss: 0.3819\n",
      "06/06 15:36:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet50_fruit30_20230606_153206\n",
      "06/06 15:36:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "06/06 15:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][ 5/41]    eta: 0:00:06  time: 0.1446  data_time: 0.0257  memory: 1211  \n",
      "06/06 15:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][10/41]    eta: 0:00:04  time: 0.1499  data_time: 0.0258  memory: 615  \n",
      "06/06 15:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][15/41]    eta: 0:00:03  time: 0.1256  data_time: 0.0006  memory: 615  \n",
      "06/06 15:36:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][20/41]    eta: 0:00:02  time: 0.1254  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][25/41]    eta: 0:00:02  time: 0.1252  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][30/41]    eta: 0:00:01  time: 0.1252  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][35/41]    eta: 0:00:00  time: 0.1251  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][40/41]    eta: 0:00:00  time: 0.1250  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][41/41]    accuracy/top1: 91.8273  accuracy/top5: 99.0748  data_time: 0.0065  time: 0.1287\n",
      "06/06 15:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain/work_dirs/best_accuracy_top1_epoch_4.pth is removed\n",
      "06/06 15:36:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 91.8273 accuracy/top1 at 5 epoch is saved to best_accuracy_top1_epoch_5.pth.\n",
      "06/06 15:36:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 5/96]  lr: 1.0000e-03  eta: 0:03:16  time: 0.4013  data_time: 0.0251  memory: 2943  loss: 0.4177\n",
      "06/06 15:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][10/96]  lr: 1.0000e-03  eta: 0:03:14  time: 0.4252  data_time: 0.0251  memory: 2943  loss: 0.4248\n",
      "06/06 15:36:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][15/96]  lr: 1.0000e-03  eta: 0:03:12  time: 0.4018  data_time: 0.0012  memory: 2943  loss: 0.4486\n",
      "06/06 15:36:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][20/96]  lr: 1.0000e-03  eta: 0:03:10  time: 0.4020  data_time: 0.0013  memory: 2943  loss: 0.3751\n",
      "06/06 15:36:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][25/96]  lr: 1.0000e-03  eta: 0:03:08  time: 0.4021  data_time: 0.0013  memory: 2943  loss: 0.3102\n",
      "06/06 15:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][30/96]  lr: 1.0000e-03  eta: 0:03:05  time: 0.4019  data_time: 0.0013  memory: 2943  loss: 0.3113\n",
      "06/06 15:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][35/96]  lr: 1.0000e-03  eta: 0:03:03  time: 0.4018  data_time: 0.0012  memory: 2943  loss: 0.3233\n",
      "06/06 15:36:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][40/96]  lr: 1.0000e-03  eta: 0:03:01  time: 0.4018  data_time: 0.0011  memory: 2943  loss: 0.3709\n",
      "06/06 15:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][45/96]  lr: 1.0000e-03  eta: 0:02:59  time: 0.4018  data_time: 0.0011  memory: 2943  loss: 0.3237\n",
      "06/06 15:36:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][50/96]  lr: 1.0000e-03  eta: 0:02:57  time: 0.4020  data_time: 0.0012  memory: 2943  loss: 0.2791\n",
      "06/06 15:36:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][55/96]  lr: 1.0000e-03  eta: 0:02:55  time: 0.4022  data_time: 0.0013  memory: 2943  loss: 0.3539\n",
      "06/06 15:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][60/96]  lr: 1.0000e-03  eta: 0:02:53  time: 0.4021  data_time: 0.0012  memory: 2943  loss: 0.3631\n",
      "06/06 15:36:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][65/96]  lr: 1.0000e-03  eta: 0:02:51  time: 0.4020  data_time: 0.0012  memory: 2943  loss: 0.3117\n",
      "06/06 15:36:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][70/96]  lr: 1.0000e-03  eta: 0:02:49  time: 0.4019  data_time: 0.0012  memory: 2943  loss: 0.3898\n",
      "06/06 15:36:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][75/96]  lr: 1.0000e-03  eta: 0:02:46  time: 0.4019  data_time: 0.0011  memory: 2943  loss: 0.4105\n",
      "06/06 15:36:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][80/96]  lr: 1.0000e-03  eta: 0:02:44  time: 0.4018  data_time: 0.0011  memory: 2943  loss: 0.3472\n",
      "06/06 15:36:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][85/96]  lr: 1.0000e-03  eta: 0:02:42  time: 0.4019  data_time: 0.0011  memory: 2943  loss: 0.3914\n",
      "06/06 15:36:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][90/96]  lr: 1.0000e-03  eta: 0:02:40  time: 0.4017  data_time: 0.0011  memory: 2943  loss: 0.3781\n",
      "06/06 15:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][95/96]  lr: 1.0000e-03  eta: 0:02:38  time: 0.4017  data_time: 0.0010  memory: 2943  loss: 0.3391\n",
      "06/06 15:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: resnet50_fruit30_20230606_153206\n",
      "06/06 15:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][ 5/41]    eta: 0:00:06  time: 0.1432  data_time: 0.0234  memory: 1211  \n",
      "06/06 15:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][10/41]    eta: 0:00:04  time: 0.1487  data_time: 0.0234  memory: 615  \n",
      "06/06 15:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][15/41]    eta: 0:00:03  time: 0.1252  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][20/41]    eta: 0:00:02  time: 0.1250  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][25/41]    eta: 0:00:02  time: 0.1254  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][30/41]    eta: 0:00:01  time: 0.1252  data_time: 0.0005  memory: 615  \n",
      "06/06 15:36:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][35/41]    eta: 0:00:00  time: 0.1251  data_time: 0.0005  memory: 615  \n",
      "06/06 15:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][40/41]    eta: 0:00:00  time: 0.1252  data_time: 0.0005  memory: 615  \n",
      "06/06 15:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][41/41]    accuracy/top1: 92.4441  accuracy/top5: 99.2290  data_time: 0.0060  time: 0.1283\n",
      "06/06 15:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain/work_dirs/best_accuracy_top1_epoch_5.pth is removed\n",
      "06/06 15:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 92.4441 accuracy/top1 at 6 epoch is saved to best_accuracy_top1_epoch_6.pth.\n",
      "06/06 15:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 5/96]  lr: 1.0000e-03  eta: 0:02:36  time: 0.3981  data_time: 0.0224  memory: 2943  loss: 0.3194\n",
      "06/06 15:37:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][10/96]  lr: 1.0000e-03  eta: 0:02:33  time: 0.4222  data_time: 0.0224  memory: 2943  loss: 0.3215\n",
      "06/06 15:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][15/96]  lr: 1.0000e-03  eta: 0:02:31  time: 0.4014  data_time: 0.0011  memory: 2943  loss: 0.3492\n"
     ]
    }
   ],
   "source": [
    "!/root/miniconda3/envs/myconda/bin/mim train mmpretrain myconfig/resnet50_fruit30.py --work-dir=work_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fb2c42-a5f4-4de4-9f69-b42e60711942",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/06 14:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 2102026003\n",
      "    GPU 0: NVIDIA A16\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.3, V11.3.109\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.12.1+cu113\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu113\n",
      "    OpenCV: 4.6.0\n",
      "    MMEngine: 0.7.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: None\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "06/06 14:39:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "model = dict(\n",
      "    type='ImageClassifier',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(3, ),\n",
      "        style='pytorch'),\n",
      "    neck=dict(type='GlobalAveragePooling'),\n",
      "    head=dict(\n",
      "        type='LinearClsHead',\n",
      "        num_classes=30,\n",
      "        in_channels=2048,\n",
      "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "        topk=(1, 5)),\n",
      "    init_cfg=dict(\n",
      "        type='Pretrained',\n",
      "        checkpoint=\n",
      "        ' https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'\n",
      "    ))\n",
      "dataset_type = 'CustomDataset'\n",
      "data_preprocessor = dict(\n",
      "    num_classes=1000,\n",
      "    mean=[123.675, 116.28, 103.53],\n",
      "    std=[58.395, 57.12, 57.375],\n",
      "    to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='RandomResizedCrop', scale=224),\n",
      "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "    dict(type='PackInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='PackInputs')\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/fruit_dataset/training_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='RandomResizedCrop', scale=224),\n",
      "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True))\n",
      "val_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/friut_dataset/val_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "val_evaluator = dict(type='Accuracy', topk=(1, 5))\n",
      "test_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    persistent_workers=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/friut_dataset/val_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "test_evaluator = dict(type='Accuracy', topk=(1, 5))\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001))\n",
      "param_scheduler = dict(\n",
      "    type='MultiStepLR', by_epoch=True, milestones=[30, 60, 90], gamma=0.1)\n",
      "train_cfg = dict(by_epoch=True, max_epochs=200, val_interval=1)\n",
      "val_cfg = dict()\n",
      "test_cfg = dict()\n",
      "default_scope = 'mmpretrain'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=20),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', interval=50, save_best='auto'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='VisualizationHook', enable=False))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='UniversalVisualizer', vis_backends=[dict(type='LocalVisBackend')])\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume = False\n",
      "randomness = dict(seed=None, deterministic=False)\n",
      "launcher = 'none'\n",
      "work_dir = 'work_dirs'\n",
      "\n",
      "06/06 14:39:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "06/06 14:39:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/registry/build_functions.py\", line 122, in build_from_cfg\n",
      "    obj = obj_cls(**args)  # type: ignore\n",
      "  File \"/mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/mmpretrain/datasets/custom.py\", line 219, in __init__\n",
      "    self.full_init()\n",
      "  File \"/mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/mmpretrain/datasets/base_dataset.py\", line 178, in full_init\n",
      "    super().full_init()\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/dataset/base_dataset.py\", line 301, in full_init\n",
      "    self.data_list = self.load_data_list()\n",
      "  File \"/mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/mmpretrain/datasets/custom.py\", line 264, in load_data_list\n",
      "    samples = self._find_samples()\n",
      "  File \"/mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/mmpretrain/datasets/custom.py\", line 224, in _find_samples\n",
      "    classes, folder_to_idx = find_folders(self.img_prefix)\n",
      "  File \"/mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/mmpretrain/datasets/custom.py\", line 31, in find_folders\n",
      "    folders = list(\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/fileio/backends/local_backend.py\", line 527, in _list_dir_or_file\n",
      "    for entry in os.scandir(dir_path):\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/friut_dataset/val_set/'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain/tools/train.py\", line 159, in <module>\n",
      "    main()\n",
      "  File \"/mnt/openmmlab-Camp/02-mmpretrain-task/mmpretrain/tools/train.py\", line 155, in main\n",
      "    runner.train()\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/runner/runner.py\", line 1701, in train\n",
      "    self._val_loop = self.build_val_loop(\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/runner/runner.py\", line 1528, in build_val_loop\n",
      "    loop = ValLoop(\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/runner/loops.py\", line 335, in __init__\n",
      "    super().__init__(runner, dataloader)\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/runner/base_loop.py\", line 26, in __init__\n",
      "    self.dataloader = runner.build_dataloader(\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/runner/runner.py\", line 1346, in build_dataloader\n",
      "    dataset = DATASETS.build(dataset_cfg)\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/registry/registry.py\", line 548, in build\n",
      "    return self.build_func(cfg, *args, **kwargs, registry=self)\n",
      "  File \"/root/miniconda3/envs/myconda/lib/python3.9/site-packages/mmengine/registry/build_functions.py\", line 144, in build_from_cfg\n",
      "    raise type(e)(\n",
      "FileNotFoundError: class `CustomDataset` in mmpretrain/datasets/custom.py: [Errno 2] No such file or directory: 'data/friut_dataset/val_set/'\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "!/root/miniconda3/envs/myconda/bin/python tools/train.py \\\n",
    "    myconfig/resnet50_fruit30.py \\\n",
    "    --work-dir=work_dirs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
