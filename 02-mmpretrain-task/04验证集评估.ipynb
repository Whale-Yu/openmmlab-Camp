{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9014ab52-1132-4432-b171-669ed89adabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('mmpretrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23db101a-f427-4038-854e-351736f5818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing command is /root/miniconda3/envs/myconda/bin/python /mnt/openmmlab-Camp/02-mmpretrain-tutorial/mmpretrain/mmpretrain/.mim/tools/test.py myconfig/resnet50_fruit30.py work_dirs/best_accuracy_top1_epoch_8.pth --launcher none. \n",
      "06/07 00:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.13 (main, Aug 25 2022, 23:26:10) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 2015610949\n",
      "    GPU 0: NVIDIA A16\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.3, V11.3.109\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.12.1+cu113\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.1+cu113\n",
      "    OpenCV: 4.6.0\n",
      "    MMEngine: 0.7.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: None\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "06/07 00:39:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "model = dict(\n",
      "    type='ImageClassifier',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(3, ),\n",
      "        style='pytorch'),\n",
      "    neck=dict(type='GlobalAveragePooling'),\n",
      "    head=dict(\n",
      "        type='LinearClsHead',\n",
      "        num_classes=30,\n",
      "        in_channels=2048,\n",
      "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "        topk=(1, 5)),\n",
      "    init_cfg=dict(\n",
      "        type='Pretrained',\n",
      "        checkpoint=\n",
      "        'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_8xb32_in1k_20210831-ea4938fc.pth'\n",
      "    ))\n",
      "dataset_type = 'CustomDataset'\n",
      "data_preprocessor = dict(\n",
      "    num_classes=1000,\n",
      "    mean=[123.675, 116.28, 103.53],\n",
      "    std=[58.395, 57.12, 57.375],\n",
      "    to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='RandomResizedCrop', scale=224),\n",
      "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "    dict(type='PackInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='PackInputs')\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/fruit30_dataset/training_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='RandomResizedCrop', scale=224),\n",
      "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True))\n",
      "val_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/fruit30_dataset/val_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "val_evaluator = dict(type='Accuracy', topk=(1, 5))\n",
      "test_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=32,\n",
      "    num_workers=5,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_root='data/fruit30_dataset/val_set',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='ResizeEdge', scale=256, edge='short'),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='PackInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "test_evaluator = dict(type='Accuracy', topk=(1, 5))\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001))\n",
      "param_scheduler = dict(\n",
      "    type='MultiStepLR', by_epoch=True, milestones=[30, 60, 90], gamma=0.1)\n",
      "train_cfg = dict(by_epoch=True, max_epochs=10, val_interval=1)\n",
      "val_cfg = dict()\n",
      "test_cfg = dict()\n",
      "default_scope = 'mmpretrain'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=5),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', interval=5, save_best='auto'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='VisualizationHook', enable=False))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='UniversalVisualizer', vis_backends=[dict(type='LocalVisBackend')])\n",
      "log_level = 'INFO'\n",
      "load_from = 'work_dirs/best_accuracy_top1_epoch_8.pth'\n",
      "resume = False\n",
      "randomness = dict(seed=None, deterministic=False)\n",
      "launcher = 'none'\n",
      "work_dir = './work_dirs/resnet50_fruit30'\n",
      "\n",
      "06/07 00:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "06/07 00:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Loads checkpoint by local backend from path: work_dirs/best_accuracy_top1_epoch_8.pth\n",
      "06/07 00:39:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/best_accuracy_top1_epoch_8.pth\n",
      "/root/miniconda3/envs/myconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "06/07 00:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 5/41]    eta: 0:00:41  time: 1.1401  data_time: 0.5519  memory: 427  \n",
      "06/07 00:39:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [10/41]    eta: 0:00:19  time: 0.6316  data_time: 0.2762  memory: 427  \n",
      "06/07 00:39:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [15/41]    eta: 0:00:12  time: 0.1226  data_time: 0.0005  memory: 427  \n",
      "06/07 00:39:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [20/41]    eta: 0:00:07  time: 0.1225  data_time: 0.0005  memory: 427  \n",
      "06/07 00:39:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [25/41]    eta: 0:00:05  time: 0.1228  data_time: 0.0005  memory: 427  \n",
      "06/07 00:39:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [30/41]    eta: 0:00:03  time: 0.1226  data_time: 0.0005  memory: 427  \n",
      "06/07 00:39:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [35/41]    eta: 0:00:01  time: 0.1227  data_time: 0.0004  memory: 427  \n",
      "06/07 00:39:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [40/41]    eta: 0:00:00  time: 0.1227  data_time: 0.0004  memory: 427  \n",
      "06/07 00:39:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [41/41]    accuracy/top1: 92.5983  accuracy/top5: 99.1519  data_time: 0.0677  time: 0.2455\n",
      "\u001b[32mTesting finished successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/root/miniconda3/envs/myconda/bin/mim test mmpretrain myconfig/resnet50_fruit30.py --checkpoint work_dirs/best_accuracy_top1_epoch_8.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
